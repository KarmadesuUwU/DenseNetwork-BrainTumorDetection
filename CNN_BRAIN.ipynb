{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"data_class\">CNN model to identify brain Tumors</h2>\n",
    "\n",
    "    Created by Rafael A.H. in Oct. 2024\n",
    "    Dataset by Preet Viradiya from Kaggle 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural network created with pytorch to detect and classify brain tumors from MRI scans\n",
    "\n",
    "1.- Libraries>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------Libraries----------------------------------------------------------------\n",
    "#Data Manipulation (General)\n",
    "import matplotlib.pylab as plt                         \n",
    "import numpy as np                                      \n",
    "import os                                               \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import itertools \n",
    "\n",
    "#Data Manipulation (Pytorch)\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
    "from torchvision import utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Pytorch model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Data obtention, I call upon the Dataset to bring forth the images which will be used to train and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0            image  class format mode          shape\n",
      "0           0   Cancer (1).jpg  tumor   JPEG  RGB  (512, 512, 3)\n",
      "1           1   Cancer (1).png  tumor    PNG    L     (300, 240)\n",
      "2           2   Cancer (1).tif  tumor   TIFF  RGB  (256, 256, 3)\n",
      "3           3  Cancer (10).jpg  tumor   JPEG  RGB  (512, 512, 3)\n",
      "4           4  Cancer (10).tif  tumor   TIFF  RGB  (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Data call\n",
    "Metadata_DF = pd.read_csv('metadata.csv')\n",
    "print(Metadata_DF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function to transform the data and work with the images in any position, as well as transforming them to tensors and normalize them with te standars values of an RGB Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Data transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225]) #Values standard for RGB\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part I am going to merge the images in one defining as positive those images where is a tumor and negative those which are healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4432\n"
     ]
    }
   ],
   "source": [
    "#Image and data merge\n",
    "dir=''\n",
    "positive=\"Brain Tumor\"\n",
    "negative='Healthy'\n",
    "\n",
    "positive_file_path=os.path.join(dir,positive)\n",
    "negative_file_path=os.path.join(dir,negative)\n",
    "positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "number_of_samples=len(positive_files)+len(negative_files)\n",
    "print(number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files=[None]*number_of_samples\n",
    "all_files[::2]=positive_files\n",
    "all_files[1::2]=negative_files \n",
    "#torch.LongTensor\n",
    "self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "self.Y[::2]=1\n",
    "self.Y[1::2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an object of the custom dataset for the train and validation.\n",
    "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"train\"), transform=transform) \n",
    "train_set.transform\n",
    "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"val\"), transform=transform)\n",
    "val_set.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Data loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Training\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Evaluating\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Visualisation\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
